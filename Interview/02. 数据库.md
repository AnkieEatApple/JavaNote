## 数据库.md
##### 1. 目录

- [一、数据库架构](#framework)
- [二、优化你的索引](#search)
	- [2.1 运用二叉查找树](#serachTree)
	- [2.2 运用B树](#BTree)
	- [2.3 运用B+树](#BPlusTree)
	- [2.4 运用Hash以及BitMap](#Hash)
- [三、密集索引和稀疏索引的区别](#distinction)
- [四、索引额外的问题](#quesiton)
	* [4.1 调优sql](#sql)
	* [4.2 左匹配原则的成因](#reasion)
	* [4.3 索引是建立越多越好吗](#rebuild)
- [五、锁模块](#lock)
	- [5.1 锁模块-MyISAM与InnoDB关于锁方面的区别](#myIsam)
	- [5.2 锁模块-数据库事务的四大特征](#event)
	- [5.3 锁模块-事物并发访问产生的问题以及事物隔离机制](#intercurrent)
	- [5.4 锁模块-当前读和快照读](#read)
	- [5.5 锁模块-RR如何避免幻读](#wrongread)
- [六、关键语法讲解](#grammer)

	

### 一、<span id="framework">数据库架构</span>
1. 关系型数据库的主要考点<br/>![WeChat3ae3e70b5b7ddae0d607038f38f19a40.png](https://i.loli.net/2019/09/12/lUSaqYizudFpmKX.png)

#### 1.1 问题1: 如何设计一个关系型数据库
1. **储存**部分：储存我们的数据，RDBMS，需要有储存(文件系统，存储在机械硬盘或者SSD固态硬盘中)和程序实例
2. **程序实例**部分：
	2. 存储管理：**磁盘IO速率往往是影响程序执行速度的主要瓶颈**，读取机械硬盘和SSD速度都**比内存小**，一次IO读取单行和多行速度差不多
	3. 缓存机制：优化执行效率，引入缓存机制，吧取出来的数据块放在缓存里，需要直接从内存返回
	4. SQL解析：将sql缓存到我们的缓存里，可以优化。缓存不宜过大，有淘汰机制
	5. 日志管理，binlog机制，记录操作的历史
	6. 权限划分，多用户管理的权限划分
	7. 容灾机制，灾难恢复模块
	8. 索引管理：优化查找效率的索引模块
	9. 锁管理：支持并发操作的锁模块
3. 图示关系为：<br/>

#### 1.2 索引模块
1. 常见问题
	1. 为什么要使用索引
	2. 什么样的信息能成为索引
	3. 索引的数据结构
	4. 密集索引和稀疏索引的区别

##### 1.2.1 为什么要使用索引
1. 最简单的数据查询方式是**全表扫描**，即将整张表或分批次加载到内存当中
2. 储存的最小单位是**块**或者**页**，它们是由多行数据组成的，将这些块都加载进来，然后逐个块去轮训，找到我们要的目标并返回。这种适合比较少量的数据，不适用大量的数据
3. 索引的目的是为了在大量的数据中，快速查询数据

##### 1.2.2 什么样的信息能成为索引
1. 主键、唯一键以及普通键等可以成为索引

##### 1.2.3 索引的数据结构
1. 生成索引，建立二叉查找树进行二分查找
2. 生成索引，建立B-Tree结构进行查找
3. 生成索引，建立B+-Tree结构进行查找
4. 生成索引，建立Hash结构进行查找

  




### 二、<span id="search">优化你的索引</span>

##### 1. 目录
- [2.1 运用二叉查找树](#serachTree)
- [2.2 运用B树](#BTree)
- [2.3 运用B+树](#BPlusTree)
- [2.4 运用Hash以及BitMap](#Hash)


#### 2.1 <span id="serachTree">运用二叉查找树</span>
1. 二叉查找树(Binary Search Tree)，又称二叉搜索树，二叉排序树，通常只有leftTree和rightTree两个节点
3. 这个二叉树，不仅仅是搜索二叉树，还是**平衡二叉树**，平衡二叉树的任意一个左子树，它的高度均不操过1，根部的左子树和根部的右子树最大差1
4. 查找的数据的方式是二分查找，算法的复杂度是O(logn)
5. 若是早CRUD操作中，删除了某些及节点，又添加了某些节点，可能会造成查找树变成线性树，时间复杂度变为了O(n)<br/>![WeChatc3f4adf4846958a476a0532b9b68da39.png](https://i.loli.net/2019/09/12/cYmQGeyHP83S17n.png)
6. **解决办法**1: 可以通过树的旋转，来将查找树改变为平衡树，这样时间复杂度会降下来，为O(logn)
7. **索引的运行瓶颈在IO**，索引快在磁盘中，先发生的事将5读入到内存中，再将7读入到内存，然后再读6到内存中，这样随着数据的增多，树的深度也会增大，检索的效率不比全表检索快
8. **解决办法**2: **如何既减少事件复杂度，同时减少IO读取次数**，就是将树矮一些，同时树存储的数据多一些


#### 2.2 <span id="BTree">运用B树</span>
1. B-Tree的结构，图示是一个三阶B树的样子，正常情况下，每个字节点的数量是很大于3的<br/>![WeChat1ae60da01a39fd2e807bd7c128ac9b05.png](https://i.loli.net/2019/09/12/kldJ31q9oeFtKy7.png)

2. 定义
	* 根节点至少包括两个孩子，存在非跟非叶子节点
	* 树中每个节点最多有m个孩子(m >= 2)
	* 除根节点和叶节点外，其他每个节点至少有ceil(m/2)个孩子，这里ceil向上取整
	* 所有叶子节点都位于同一层

3. 假设每个非终端节点中包含有n个关键字信息，其中
	1. Ki(i=1...n)为关键字，且关键字按顺序生序排序K(i-1) < Ki，升序排列的
	2. 关键字的个数n必须满足：[ceil(m/2) - 1] <= n <= m-1，关键字个数比孩子节点个数少一个
	3. 非叶子节点的指针：P[1], P[2], ..., P[M]; 其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其他P[i]指向关键字属于(K[i-1], K[i])的子树
4. B数可以通过合并、上移、下移、分裂等方法避免线性树的产生  

#### 2.3 <span id="BPlusTree">运用B+树</span>
1. B+数是B数的变体，其定义基本与B数相同，除了：
	* 非叶子节点的子树指针与关键字个数相同
	* 非叶子节点的子树指针P[i]，指向关键字值[K[i], K[i + 1]]的子树
	* 非叶子节点仅用来索引，数据都保存在叶子节点中
	* 所有叶子节点均有一个连指针指向下一个叶子节点，并按大小顺序链接，这样可以支持范围统计，可以横向的跨子树进行统计
2. B+树的图示<br/>![WeChatcd179df89460a538b498753fed27e21a.png](https://i.loli.net/2019/09/12/YwJsW5e3vVGECLc.png)

3. B+Tree更适合用来做存储索引
	* B+树的磁盘读写代价更低
	* B+数的查询效率更加稳定
	* B+树更有利于对数据库的扫描，更适用于范围查询 


#### 2.4 <span id="Hash">运用Hash以及BitMap</span>
1. Hash索引的图示<br/>![WeChatffb8097c9be5b52d7c98d31d7262cd7b.png](https://i.loli.net/2019/09/12/F69bln4KGYWHzJU.png)
2. 缺点
	* 仅仅能满足“=”，“IN”，不能使用范围查询
	* 无法被用来避免数据的排序操作
	* 不能利用部分索引键查询
	* 不能避免表扫描，
	* 遇到大量Hash值相等的情况后，性能并不一定就会比BTree索引高，bucket桶可能存在重复，之后会形成线性链表或树结构等

3. BitMap索引，只有Oracle支持，图示<br/>![WeChat15e6bd0b79a89d1ee6396d5740c6bf10.png](https://i.loli.net/2019/09/12/WHalozKyCsP64BO.png)

4. BitMap索引类似于B+索引，通过Byte位来查找，所以操作比较快
5. 锁的粒度非常的大，若改变一个位，整个位图就需要全部锁定，这样就不是很适合高并发操作

### 三、<span id="distinction">密集索引和稀疏索引的区别</span>
1. 密集索引和稀疏索引的区别
	* 密集索引文件中的每个搜索码都对应一个索引值
	* 稀疏索引文件只为索引码的某些值建立索引项

2. 图示<br/>![WeChataef5c4f9e3ad3d22e2a0933f8238d211.png](https://i.loli.net/2019/09/12/xfy83rIV6jngKuY.png)
3. **密集索引**：叶子节点保存的不仅仅是键值，还保存了位于同一行记录里的其他列的信息，由于密集索引决定了表的物理排列顺序，一个表只能有一个物理排列顺序，所以一个表只能创建一个密集索引
4. **稀疏索引**：叶子节点仅保存了键位信息，以及该行数据的地址，某些稀疏索引仅保持了键位信息和及其主键

#### 3.1 对MySql的搜索引擎具体分析
1. MySql主要由两种引擎，一种是MyISAM，另一种是InnoDB，这两种是主流
2. MyISAM不管是主键索引、唯一键索引或者普通索引，其索引均属于稀疏索引
3. InnoDB有且仅有一个密集索引
	* 若一个主键被定义，该主键则为密集索引
	* 若没有主键被定义，该表的第一个唯一非空索引则为密集索引
	* 若不满足以上条件，InnoDB内部会生成一个隐藏主键(密集索引)，是一个6字节的列，会随着数据的插入而自增
	* 非主键索引存储相关键位和其对应的主键值，包含两次查找， 一次是查找次级索引自身，一次是查找主键
4. 额外的知识<br/>![WeChat9911c36dc70161383af5a128cdff0f57.png](https://i.loli.net/2019/09/12/5MhxkrSuP1eDn9f.png)
5. InnoBD，使用的是密集索引，将主键组织到一棵B+树中，而行数据就存储在叶子节点上，因为InnoDB的主键索引和对应的数据是保存在同一个文件当中的，所以检索的时候，在加载叶子节点的主键加入内存的同时，也加载了对应的数据。<br/>eg：按照上面的图片，就是where id=14这样的条件查询主键，按照B+树的查找算法，可以查找对应的叶子节点，并获得对应的行数据，
6. InnoDB，若对稀疏索引进行条件筛选，则需要进行两个步骤， 
	* 第一步在稀疏索引的B+树中检索该键，比如Elison这个主键信息14
	* 第二步再执行B+树中的检索操作，然后到达叶子节点获取整行的数据
7. MyISAM，使用的都是稀疏索引，稀疏索引的两个B+树结构没有什么不同，节点的结构类似，只是存储的数据不一样而已，主键索引存储的是主键，辅助键索引存储的是辅助键，对于表中数据，这两个键没有任何的区别

#### 3.2 对myISAM和InnoDB不同驱动下的文件细分区别
1. 打开`data/database_demo/`，也就是创建的数据库的名称对应的目录下，不同的驱动对应不同的文件
	* 两个驱动的创建表的结构都存储在`*.frm`文件里
	* myISAM中，文件`*.idb`是数据和索引存在一起的
	* InnoDB中，文件`*.MYI`存的是索引，文件`*.MYD`存储的是数据  

### 四、<span id="quesiton">索引额外的问题</span>
1. 问题回顾总结
	* 为什么要使用索引
		* 因为索引能避免我们进行全表扫描去查找数据，提升检索效率
	* 什么样的信息能成为索引
		* 主键、唯一键等，只要是能让数据具备唯一区分性的字段都能成为索引
	* 索引的数据结构
		* 主流是B+树，还有Hash结构和BitMap等，其中MySQL数据库不支持BitMap索引，同时基于InnoDB和MyISAM引擎的MySQL不显示的支持Hash
	* 密集索引和稀疏索引的区别
		* 上一节有提到
2. 衍生出来的问题，以MySQL为例
	* 如何定位并优化慢查询Sql
	* 联合索引的最左匹配原则的成因
	* 索引是建立的越多越好吗？
3. 目录
	* [4.1 调优sql](#sql)
	* [4.2 左匹配原则的成因](#reasion)
	* [4.3 索引是建立越多越好吗](#rebuild)

#### 4.1 <span id="sql">调优sql-如何定位并优化慢查询Sql</span>
1. 具体的场景具体分析，只是描述大致思路
	1. 根据慢日志定位慢查询sql
	2. 使用explain等工具分析sql
	3. 修改sql或者尽量让sql走索引

2. 


#### 4.2 <span id="reasion">联合索引最左匹配原则的成因</span>




#### 4.3 <span id="rebuild">索引是建立越多越好吗</span>


### 五、<span id="lock">锁模块</span>
1. 常见问题
	* MyISAM与InnoDB关于锁方面的区别是什么
	* 数据库事物的四大特性
	* 事务隔离级别以及各级别下的并发访问问题
	* InnoDB可重复读隔离级别下如何避免幻读
	* RC、RR级别下的InnoDB的非阻塞如何实现

#### 5.1 <span id="myIsam">锁模块-MyISAM与InnoDB关于锁方面的区别</span>
1. MyISAM默认用的是表级锁，不支持行级锁
2. InnoDB默认的是行级锁，也支持表级锁

##### 5.1.1 对表级锁、行级锁、读锁、写锁的分析
1. **背景**：一般都是发生在多个进程同时访问数据库表中的内容的时候发生的block的事件，也就是多个进程可能同时操作同一张表，或同一张表中的不同数据，这了分别针对不同的情况对上面形容的锁进行了分析。
2. **条件**：
	1. 需要开启不同的session来访问对应的数据库，这里取`database_demo`，里面同时存在两个表格，分别注入20000000+条数据
	2. 一个表格`persion_info_myisam`的驱动为myISAM，另一个的表格`persion_info_innodb`驱动为InnoDB
	3. 表格的结构都相同，主键和表结构都相同，只是驱动不同，其中myISAM的表格格式为<br/>

	```
	CREATE TABLE `person_info_myisam` (
		`id` int(7) NOT NULL AUTO_INCREMENT,
		`account` varchar(10) DEFAULT NULL,
		`name` varchar(20) DEFAULT NULL,
		`area` varchar(20) DEFAULT NULL,
		`title` varchar(20) DEFAULT NULL,
		`motto` varchar(50) DEFAULT NULL,
		PRIMARY KEY (`id`),
		UNIQUE KEY `account`(`account`),
		KEY `index_area_title`(`area`, `title`)
	) ENGINE=MyISAM AUTO_INCREMENT=2428582 DEFAULT CHAREST=utf8;
	```

3. **准备**
	1. `SELECT count(*) from person_info_innodb;`
	2. `SELECT count(*) from person_info_myisam;`
	3. 可以查询现有两张表分别总共存在多少条数据
	4. 数据量在200多w的时候，在查询和更改表中的数据的时候，都需要几秒钟的时间，利用这几秒钟的时间，利用别的session来继续访问，可以制造出并发访问的场景
4. **MyISAM分析**
	1. `select * from person_info_myisam where id between 1 and 2000000;`，查询id为1～20000000之间的数据，执行起来大约需要5～6秒
	2. `updata person_info_myisam set account = account where id = 2000001;`，将id=20000001的行的acccount的值重新赋值给account，单独执行特别的快
	3. 在执行1中select语句的时候，紧接着执行2的update语句，会发现2语句被block住，等待1语句执行完之后执行2语句
	4. 当表进行查询的时候，myisam会自动的给表上了一个表锁，它会锁住这张表，并且去block其他的session对其进行数据的更新
	5. **主要原因为，myisam在select操作的时候，会自动为我们增加一个表级的读锁，而对数据进行增删改的时候，它会为我们的表增加一个表级别的写锁；当读锁未被释放的时候，另一个session想要对表加上写锁，它就会被阻塞，知道所有的读锁都被释放为止**
	6. **如何显示给表加上读锁**？`lock tables person_info_myisam read(write);`，此时对此表进行update或其他写锁的更新，同样会被block住，然后调用`unlock tables`，就会释放读锁
	7. `select * from person_info_myisam where id in (2000001);`，查询id为2000001行的数据，单独执行很快
	8. **读锁又可以成为共享锁**，在进行范围查询的时候，虽然加了读锁，依然可以对表里的数据进行读操作，例如操作7
	9. `update person_info_myisam set account = account where id between 1 and 2000000;`，对id为1～2000000的数据重新赋值account，这个语句也非常浪费时间
	10. 在执行操作9的时候，然后紧接着执行操作7，会发现操作7会被block住，当已经上了写锁，再上读锁就不可能，就会被block，需要等待释放
	11. 在执行操作9的时候，然后执行2的时候，还是会block住，也就是先上写锁，再上写锁，是不可能的，所以**写锁，又名排它锁**
	12. **对于select的读锁可不可以变为排它锁**？答案是可以的，可以将原来的select语句更改为`select * from person_info_myisam where id between 1 and 2000000 for update;`，调用这个语句就会产生排它锁的效果
5. **MyISAM总结**
	1. MyISAM默认支持表级锁，不支持行级锁，表级锁会锁住整张表
	2. 锁有两种，共享锁和排它锁，共享锁可以再上共享锁，但是共享锁不能再上排它锁，排它锁也不能再上共享锁，也不能再上排它锁。这种锁的关系同样适用于InnoDB。
6. **InnoDB分析**
	1. InnoDB支持事物，MySQL是支持自动提交事务的
	2. `update person_info_innodb set title = "test" where id = 1;`，改变id为1的title的数据。执行这个操作紧接着在另一个session执行这个语句，没有block住，看起来和ISAM一样，都是自动执行的，sql语句跑完之后就会自动解锁
	3. InnoDB用的是二段锁，**二段锁指加锁和解锁是分成两个步骤来进行的，即先对同一个事务里的一批操作分别进行加锁，在commit的时候在对事务里加上的锁进行统一的解锁**。而当前的commit是自动提交的，所以看起来和myISAM没有太大的区别
	4. 查看mysql中InnoDB的自动提交commit，`show variables like 'autocommit';`，可以查看当前是否为自动提交
	5. 将自动提交关闭的时候，可以运行`set autocommit = 0;`，这样子就能关闭自动提交了。关闭自动提交仅支持当前session不影响其他的session，session断开链接后，恢复自动提交。
	6. `select * from person_info_innodb where id = 3;`，注意此时commit不是自动提交，也就是二段锁中没有释放
	7. `update person_info_innodb where set title="test3" where id = 3;`，在上一个sission执行select操作之后，执行这个update语句竟然可以执行成功。主要**因为InnoDB默认未对select操作增加共享锁**，
	8. **如何对InnoDB中的select语句上共享锁**？`select * from person_info_innodb where id = 3 lock in share mode;`，执行一下这个语句，紧接着并不执行`commit;`语句不释放锁，紧接着执行语句7的操作，语句7会被block，直到上面的session内语句执行`commit;`，即读锁释放，就可以执行语句7了。
	9. **InnoDB是不是真的行级锁呢**？首先执行8语句中的句子，对3进行操作，然后执行7中的句子，将sql中的3改为4，在8句子不执行commit的时候执行，可以看到句子没有被锁住，表明InnoDB是支持行级锁的
	10. **不走索引的时候锁的情况**，
		* 执行`select * from person_info_innodb where motto="sssssddaddsad" lock in share mode;`，加读锁执行，但是不提交
		* 执行`update person_indo_innodb set title=title where motto = "dsafesadafasas";`
		* 结果是第二个被block住了，虽然没更新同一行数据的时候，但是另一个session执行第二句依然被block住了
		* 结论是：**在不走索引的时候，整张表就会被锁住，也就是此时的查询用的是表级锁，所以InnoDB在sql没有用到索引的时候呢，用的是表级锁，而sql用到索引的时候，用的是行级锁以及GAP锁**

##### 5.1.2 共享锁和排斥锁的兼容性

1. 图示所示，X表示排它锁，S表示共享锁<br/>![WeChat4feffcf4e62e360db0c79f287dccc499.png](https://i.loli.net/2019/09/14/lmTDzI87L1HVnfQ.png)
2. **行级锁是不是一定要比表级锁要好**？不一定
	* 锁的粒度越细，代价越高，相比表级锁在表的头部直接加锁来讲，行级锁还要扫描到某行的时候，对其上锁，这样代价是比较大的，InnoDB支持事务的同时，也比MyISAM带来了更大的开销
	* 从索引的部分也了解到，InnoDB是有且仅有一个聚集索引的，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高，但是辅助索引需要查两次，先查到主键，在通过主键查到数据，而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的，因此MyISAM引擎在存检索系统中，也就是增删改很少的系统中，其性能要好于InnoDB
3. MyISAM适合的场景
	* 频繁执行全表count语句。InnoDB是不保存表的具体行数的，每次都需要`select count(*) from table;`重新统计，而MyISAM，用一个变量保存了整个表的行数，执行上述语句时，只需要读出该变量即可，速度很快
	* 对数据进行增删改的频率不高，查询非常频繁。 因为增删改会涉及到锁表操作，虽然对于插入操作可以通过一些配置能够让该引擎支持从表的尾部插入数据，但是依然会产生很多碎片，所以比较影响性能，但是存查询的效率是非常高的。
	* 没有事务。适合也就是不支持事务的场景，不需要支持事务的系统也推荐使用ISAM。
4. InnoDB适合的场景
	* 数据增删改查都相当频繁。增删改的时候知识某些行被锁，在大多数情况下避免了阻塞，不想MyISAM每次直接锁整张表
	* 可靠性要求比较高，要求支持事务。


##### 5.1.3 数据库锁的分类
1. **按锁的粒度划分，可分为表级锁、行级锁、页级锁**
	* InnoDB默认支持行级锁，也支持表级锁， InnoDB对行级上锁的时候呢，会先上一种表级别的意向锁
	* MyISAM仅支持表级锁
	* 不常用的BDB引擎支持页级锁，介于表级和行级之间的锁，上面形容的逻辑块 
2. 按锁级别划分，可以为共享锁、排它锁
3. 按加锁方式划分，可分为自动锁、显示锁
	* MySQL默认的是自动锁，表级别的意向锁、MyISAM的表锁、以及insert、update、delete加上的锁就是自动锁
	* 后面添加的`select ... for update`、`lock in share mode`，这些属于显示锁
4. 按操作划分，可以分为DML锁、DDL锁
	* 对数据进行操作上的锁，就是DML锁，包括对数据的增删改查
	* 对表结构进行变更的，如调用order table，加上的锁就是DDL锁
5. 按使用方式划分，可分为乐观锁、悲观锁
	* 对外界的修改持保守态度，因此在整个数据处理过程中，将数据处于锁定状态，悲 观锁的实现往往需要数据库提供的锁机制，才能真正的保证数据访问的排他性，否则即使在系统中实现了加锁机制，也无法保证外部系统修改数据。
	* 悲观排它控制，往往是先取锁再访问的保守策略，为数据的处理安全提供了保证但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会，另外在只读型事务处理中，由于不会产生冲突，也没必要使用锁，如果上锁会增加系统负担，同时还会降低并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以去处理
	* 乐观锁相对于悲观锁而言，乐观锁认为乐观锁一般不会造成冲突，所以在数据提交更新的时候，才会在数据冲突与否进行检测，如果发现冲突了，则返回用户错误的信息，让用户决定如何去做，
	* 相对于悲观锁在对数据库进行处理的时候呢，乐观锁并不会使用数据库提供的锁机制，一般的实现乐观锁的方式呢，就是记录数据版本，实现数据版本有两种方式，一种是使用版本号，第二种是使用时间戳
6. 乐观锁的操作数据中的版本号方式原理
	* 基于数据版本的version版本实现，在表中添加了一个version字段列(DEFAULT '0')，读取数据的时候，同时将version读取出来，数据每更新一次，就对version++
	* 当提交更新的时候，去判断当前数据库表对应的记录的当前version信息与第一次取出来的version值进行比对
	* 如果与第一次取出来的version相等，则予以更新，否则认为是过期数据
7. 实现乐观锁操作数据距离
	1. 首先建立一个表`test_innodb`，设置commit为自动提交，有三列，分别为id(主键)、money、version
	2. 先读取test_innodb的数据，得到Version的值为VersionValue，`select version from test_innodb where id = 2;`，此时读取的version为0，另一个进程读取的version也是0
	3. 每次更新test_innodb表中的money字段的时候，为了防止发生冲突，先去检查version再去更新，更新成功的话，version + 1，`update test_innodb set money = 123, version = 0 + 1 where version = 0 and id = 2;`，但是程序2先执行了update，语句是`update test_innodb set money = 345, version = 0 + 1 where version = 0 and id = 2;`，这时候version已经是1了，程序1就会执行失败，影响的行数会是1。
	4. 提交失败的后面的用户程序具体逻辑看自己业务实现，乐观锁主要看这种提交的时候去检查版本，而不是在提交的时候锁住字段，去需要其他程序等待，这个就是乐观锁的实现。
	5. 乐观锁还是会存在两个进程同时提交version相同的数据的时候的。


#### 5.2 <span id="event">锁模块-数据库事务的四大特征</span>
1. ACID
	* 原子性(Atomic)，事务操作的所有操作，要么全部执行，要么全部失败回滚
	* 一致性(Consistency)，事务应确保数据库的状态，从一个一致状态，转变为另一个一致的状态，一只状态的含义是指数据库中的数据应满足完整性约束，以转账为例，用户A和用户B，两者的钱加起来一共是2000，那么不管A和B之间如何转账，转几次帐，事务结束后，两个用户的钱加起来还得是2000，这就是事务的一致性
	* 隔离性(Isolation)，多个事务并发执行时，一个事务的执行不应该影响其它事务的执行，**隔离性是重点**
	* 持久性(Durability)，一个事务一旦提交，它对数据库的修改应该永久保存在数据库中，持久性意味着当系统、或者介质发生故障时，确保已提交事务的更新，不能丢失，既对已提交事务的更新能恢复。一旦一个事务被提交，BBMS(基于总线的消息服务)必须保证提供适当的冗余，使其耐得住系统的故障，所以持久性主要在于BBMS的回复性能。InnoDB会所有的对页面的操作写入一个专门的文件，并在数据库启动时，从此文件进行恢复操作，这个文件就是**reDoLoadFile**


#### 5.3 <span id="intercurrent">锁模块-事物并发访问产生的问题以及事物隔离机制</span>
1. 主要分为两个问题：
	1. 事务并发访问可能引起的问题
	2. 避免发生这些问题中的一类或者几类
2. MySql会利用锁机制，创建出来不同的事务隔离级别，将按照事务隔离级别从低到高的顺序进行记录
	* **更新丢失**：mysql所有事务隔离级别在数据库层面上均可避免
		* lost update，即一个事务的更新覆盖了另一个事务的更新，主流数据库都会加锁避免这种更新覆盖的情况，可能发生的流程有<br/>![WeChatea64b8302c797cea1dcf1c64fbf4c1ce.png](https://i.loli.net/2019/09/14/nl18yDfdOP9VZez.png)
	* **脏读**：READ-COMMITTED事务**隔离级别以上可避免**
		* dirty read，指的是一个事务读到另一个事务未提交的数据 
		* `select @@tx_isolation;`，读取当前的事务隔离级别，默认的事务隔离界别为`REPEATABLE-READ`
		* `set session transaction isolation level read unconmitted`，将界别设定为未提交读级别设定为`READ-UNCOMMITTED`，这个是最低的事务隔离级别。
		* 创建了一张`account_innodb`表，里面有id、name、balence，分别插入了三杠数据
		* 两个程序均开启事务`start transaction;`，然后程序1执行`update account_innodb set blance = 1000 - 100 where id = 1;`，拿出100之后，在执行`select * from account_innodb where id = 1;`，此时session还没有提交
		* 程序2也执行了`select * from account_innodb where id = 1;`，发现结果是900，但是程序1还没有提交事务。
		* 若是程序1，在select之后发现网络不稳定等原因取款失败了，使用`rollback`回滚了，然后账面上就又变回1000了。
		* 但是程序2要想存入200元的时候，会按照之前900进行计算，执行`update account_innodb set balance = 900 + 200 where id = 1;`，然后commit。
		* 但是作为用户，100块取款失败后，就丢100元
	* **不可重复读**：REPEATABLE-READ事务隔离级别以上可避免
		* none repeat read，事务A多次读取同一数据，事务B在事务A多次读取数据的过程中对数据进行了更新并提交，导致事务A多次读取同一数据时，结果不一致
		* 两个程序均开启事务`start transaction;`，id为1现有1300元，程序1查询id为1的账户的balance，对1用户存入300元，`update account_innodb set balance = balance + 300 where id = 1;`
		* 此时程序2查询id为1的账户，由于当前的程序1的事务没有commit避免了脏读，程序2执行，`select * from account_innodb where id = 1;`之后，结果为1300元
		* 此时程序1，存入之后查询，`select * from account_innodb where id = 1;`，此时balance为1600元，然后提交修改commit
		* 此时程序2再次读取了一次，`select * from account_innodb where id = 1;`，此时的balance为1600元，然后commit
		* 主要是问题是程序2，在两次读取balance的时候数据不一致，也就会造成现在的数据是否真实可靠，因为两次读取的结果不同，再次读取是否还会发生改变，这就是不可重复读的问题
		* `set session transaction isolation level repeatable read;`，设置隔离级别为repatable-read
		* 不可重复读之后，select的数据是第一次读取的数据，但是修改这个数据-100之后，commit，依旧会变成理论上的程序1增加后 -100的数据。
	* **幻读**：SERIALIZABLE事务隔离级别可避免
		* 事务A读取与搜索条件匹配的若干行，事务B以插入或删除行等方式来修改事务A的结果集，导致事务A像出现幻觉一样
		* `select @@tx_isolation`，查看此时的事务级别都是`REPEATABLE-READ`，session1和session2同时开启事务，执行`start transaction`
		* `select * from account_innodb lock in share mode;`，在session1中执行这个读取操作
		* `insert into account_innodb values(4, "newman, 500")`，在session2插入newman的账户为500
		* `update account_innodb set balance = 1000;`，session1将所有的记录更新为1000，这里却显示了更新成功四条记录
		* 对这个例子来说，事务A在执行了一个当前读操作，而另一个事务B在事务A的影响区间内插入的一条数据，这时事务A再执行了一个当前读操作时，就出现了幻行，像发生了幻觉一样
		* 当然幻读也同时适用于，另外的事务对同一张表删除一行数据导致当前读出的数据莫名其妙比先前少了一行的情况
		* **上面的例子可以将隔离级别设置为READ-COMMITTED**，重复一下上面步骤，即可看到update的时候看到幻读，update影响了4行
		* 修改事务隔离界别为SERIALIZABLE，重复上面的例子，即可看到最后insert操作被block了，即使select中没有显示加锁，也会同样的被block。

3. 事务隔离级别从低到高分别是<br/>![WeChat43bb7bc6da09865e5354c259d2d458d8.png](https://i.loli.net/2019/09/14/WxGr98isvCLKb6y.png)
4. 不可重复读和幻读并不一样
	* 不可重复读，侧重对同一数据的修改
	* 幻读，侧重新增或删除
5. 不讲事务隔离级别直接设置为SERIALIZABLE是因为出于性能的考虑，界别越高，串行化执行越严重，这样就降低了数据库的并发度。因此可以根据业务的需要设置事务隔离级别
	* ORACLE默认READ_COMMITTED
	* MySql默认为REPATABLE-READ
		

#### 5.4 <span id="read">锁模块-当前读和快照读</span>




#### 5.5 <span id="wrongread">锁模块-RR如何避免幻读</span>




### 六、<span id="grammer">关键语法讲解</span>








